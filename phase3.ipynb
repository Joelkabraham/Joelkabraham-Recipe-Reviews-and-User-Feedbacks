{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e57c86-5661-405d-8314-63f10d88a386",
   "metadata": {},
   "source": [
    "Recipe Reviews and User Feedbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686311c-7caa-49c0-be3f-25b65d686bd0",
   "metadata": {},
   "source": [
    "Name: Joel K Abraham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e89df-0572-4e96-8aab-d5e8c61d39cc",
   "metadata": {},
   "source": [
    "Organisation: Entri Elevate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873145c-d176-49d5-8784-86eaf62b2424",
   "metadata": {},
   "source": [
    "Date:: 18/03/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b71a4-cefe-4d46-8863-e3d877615c53",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "The Recipe Reviews dataset comprises over 18,000 user-generated reviews that capture detailed information about recipes and user interactions. It includes identifiers such as recipe_number, recipe_code, and recipe_name, along with review-specific data like unique comment IDs, timestamps, reply counts, and engagement metrics (thumbs up and thumbs down). Additionally, it provides insights into user behavior through user IDs, names, and reputation scores, and features numerical ratings like stars and best_score, as well as the actual review text. This rich dataset is ideal for analyzing sentiment, user engagement, and trends in culinary feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8258b-9143-49e9-86ea-e5817ebf7e90",
   "metadata": {},
   "source": [
    "Objective\n",
    "\n",
    "The objective of the Recipe Reviews dataset is to provide a rich, multifaceted view of user interactions with culinary recipes, enabling the analysis of sentiment, engagement, and review quality. It is designed to support research in understanding how factors like user reputation, review ratings (such as stars and best_score), and textual feedback correlate with overall user satisfaction and recipe performance. This dataset facilitates various analytical tasks—from sentiment analysis and trend detection to the development of recommendation systems—thus offering valuable insights for both data scientists and culinary professionals looking to enhance user experience and improve recipe curation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d40c504-4ac7-491f-9c13-225bd8082b14",
   "metadata": {},
   "source": [
    "Data Description\n",
    "\n",
    "Unnamed: 0: An index column generated during data export or import.\n",
    "recipe_number: A numerical identifier for the recipe.\n",
    "recipe_code: A code representing the recipe, likely used for internal identification.\n",
    "recipe_name: The name or title of the recipe.\n",
    "comment_id: A unique identifier for each review or comment.\n",
    "user_id: A unique identifier for the user who submitted the review.\n",
    "user_name: The display name of the user.\n",
    "user_reputation: A numerical score indicating the credibility or influence of the user.\n",
    "created_at: A timestamp showing when the review was posted.\n",
    "reply_count: The number of replies or follow-up comments the review received.\n",
    "thumbs_up: The count of positive feedback received for the review.\n",
    "thumbs_down: The count of negative feedback received for the review.\n",
    "stars: The rating given to the recipe, typically on a scale (e.g., 1-5 stars).\n",
    "best_score: A computed score that might reflect the quality or relevance of the review.\n",
    "text: The actual textual content of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a279f3a-f077-4cc2-aff0-728a12bc51f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18182 entries, 0 to 18181\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       18182 non-null  int64 \n",
      " 1   recipe_number    18182 non-null  int64 \n",
      " 2   recipe_code      18182 non-null  int64 \n",
      " 3   recipe_name      18182 non-null  object\n",
      " 4   comment_id       18182 non-null  object\n",
      " 5   user_id          18182 non-null  object\n",
      " 6   user_name        18182 non-null  object\n",
      " 7   user_reputation  18182 non-null  int64 \n",
      " 8   created_at       18182 non-null  int64 \n",
      " 9   reply_count      18182 non-null  int64 \n",
      " 10  thumbs_up        18182 non-null  int64 \n",
      " 11  thumbs_down      18182 non-null  int64 \n",
      " 12  stars            18182 non-null  int64 \n",
      " 13  best_score       18182 non-null  int64 \n",
      " 14  text             18180 non-null  object\n",
      "dtypes: int64(10), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>recipe_number</th>\n",
       "      <th>recipe_code</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_reputation</th>\n",
       "      <th>created_at</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>thumbs_down</th>\n",
       "      <th>stars</th>\n",
       "      <th>best_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM</td>\n",
       "      <td>u_9iFLIhMa8QaG</td>\n",
       "      <td>Jeri326</td>\n",
       "      <td>1</td>\n",
       "      <td>1665619889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>527</td>\n",
       "      <td>I tweaked it a little, removed onions because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY</td>\n",
       "      <td>u_Lu6p25tmE77j</td>\n",
       "      <td>Mark467</td>\n",
       "      <td>50</td>\n",
       "      <td>1665277687</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>724</td>\n",
       "      <td>Bush used to have a white chili bean and it ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2FPrSGyTv7PQkZq37j92r9mYGkP</td>\n",
       "      <td>u_s0LwgpZ8Jsqq</td>\n",
       "      <td>Barbara566</td>\n",
       "      <td>10</td>\n",
       "      <td>1664404557</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>710</td>\n",
       "      <td>I have a very complicated white chicken chili ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2DzdSIgV9qNiuBaLoZ7JQaartoC</td>\n",
       "      <td>u_fqrybAdYjgjG</td>\n",
       "      <td>jeansch123</td>\n",
       "      <td>1</td>\n",
       "      <td>1661787808</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>In your introduction, you mentioned cream chee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2DtZJuRQYeTFwXBoZRfRhBPEXjI</td>\n",
       "      <td>u_XXWKwVhKZD69</td>\n",
       "      <td>camper77</td>\n",
       "      <td>10</td>\n",
       "      <td>1664913823</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>820</td>\n",
       "      <td>Wonderful! I made this for a &amp;#34;Chili/Stew&amp;#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  recipe_number  recipe_code         recipe_name  \\\n",
       "0           0              1        14299  Creamy White Chili   \n",
       "1           1              1        14299  Creamy White Chili   \n",
       "2           2              1        14299  Creamy White Chili   \n",
       "3           3              1        14299  Creamy White Chili   \n",
       "4           4              1        14299  Creamy White Chili   \n",
       "\n",
       "                                        comment_id         user_id  \\\n",
       "0  sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM  u_9iFLIhMa8QaG   \n",
       "1  sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY  u_Lu6p25tmE77j   \n",
       "2  sp_aUSaElGf_14299_c_2FPrSGyTv7PQkZq37j92r9mYGkP  u_s0LwgpZ8Jsqq   \n",
       "3  sp_aUSaElGf_14299_c_2DzdSIgV9qNiuBaLoZ7JQaartoC  u_fqrybAdYjgjG   \n",
       "4  sp_aUSaElGf_14299_c_2DtZJuRQYeTFwXBoZRfRhBPEXjI  u_XXWKwVhKZD69   \n",
       "\n",
       "    user_name  user_reputation  created_at  reply_count  thumbs_up  \\\n",
       "0     Jeri326                1  1665619889            0          0   \n",
       "1     Mark467               50  1665277687            0          7   \n",
       "2  Barbara566               10  1664404557            0          3   \n",
       "3  jeansch123                1  1661787808            2          2   \n",
       "4    camper77               10  1664913823            1          7   \n",
       "\n",
       "   thumbs_down  stars  best_score  \\\n",
       "0            0      5         527   \n",
       "1            0      5         724   \n",
       "2            0      5         710   \n",
       "3            0      0         581   \n",
       "4            0      0         820   \n",
       "\n",
       "                                                text  \n",
       "0  I tweaked it a little, removed onions because ...  \n",
       "1  Bush used to have a white chili bean and it ma...  \n",
       "2  I have a very complicated white chicken chili ...  \n",
       "3  In your introduction, you mentioned cream chee...  \n",
       "4  Wonderful! I made this for a &#34;Chili/Stew&#...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Recipe_Reviews.csv\", encoding=\"ISO-8859-1\")  # Change file format if needed\n",
    "\n",
    "# Display basic info\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7150dacb-827b-4995-95bd-91274c9fe8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0         0\n",
      "recipe_number      0\n",
      "recipe_code        0\n",
      "recipe_name        0\n",
      "comment_id         0\n",
      "user_id            0\n",
      "user_name          0\n",
      "user_reputation    0\n",
      "created_at         0\n",
      "reply_count        0\n",
      "thumbs_up          0\n",
      "thumbs_down        0\n",
      "stars              0\n",
      "best_score         0\n",
      "text               2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3307a71-4a8f-44e0-975d-e397552a91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows/columns with excessive missing data\n",
    "df.dropna(subset=[\"user_id\", \"text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b275ef1-6c2a-4ca3-99f9-ede8f2ca203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "18177    False\n",
       "18178    False\n",
       "18179    False\n",
       "18180    False\n",
       "18181    False\n",
       "Length: 18180, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69510b4-5915-4848-abca-2e7ce643644d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a7c68c-31cd-432c-8489-b0b2248ec5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1970-01-01 00:00:01.665619889\n",
       "1       1970-01-01 00:00:01.665277687\n",
       "2       1970-01-01 00:00:01.664404557\n",
       "3       1970-01-01 00:00:01.661787808\n",
       "4       1970-01-01 00:00:01.664913823\n",
       "                     ...             \n",
       "18177   1970-01-01 00:00:01.622717977\n",
       "18178   1970-01-01 00:00:01.613036720\n",
       "18179   1970-01-01 00:00:01.622717844\n",
       "18180   1970-01-01 00:00:01.622717233\n",
       "18181   1970-01-01 00:00:01.622717625\n",
       "Name: created_at, Length: 18180, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "df[\"created_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73292e81-f874-4633-862a-1305b15db167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_reputation: 1246 outliers\n",
      "reply_count: 230 outliers\n",
      "thumbs_up: 4080 outliers\n",
      "thumbs_down: 2396 outliers\n",
      "stars: 4353 outliers\n",
      "best_score: 4180 outliers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to count outliers using the IQR method\n",
    "def count_outliers(df, columns):\n",
    "    outlier_counts = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        outlier_counts[col] = len(outliers)\n",
    "    return outlier_counts\n",
    "\n",
    "# Define numerical columns to check for outliers\n",
    "numerical_columns = [\"user_reputation\", \"reply_count\", \"thumbs_up\", \"thumbs_down\", \"stars\", \"best_score\"]\n",
    "\n",
    "# Get the counts of outliers\n",
    "outlier_counts = count_outliers(df, numerical_columns)\n",
    "\n",
    "# Print out the results\n",
    "for col, count in outlier_counts.items():\n",
    "    print(f\"{col}: {count} outliers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce5d30b2-7ae0-47f0-a35a-cb09b36aa3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          2.112885\n",
       "recipe_number       0.458756\n",
       "recipe_code         3.443614\n",
       "user_reputation    33.716657\n",
       "reply_count        11.282445\n",
       "thumbs_up           8.413665\n",
       "thumbs_down        17.889305\n",
       "stars              -2.128418\n",
       "best_score          3.402349\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include = [\"number\"]).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e614694d-432f-40cd-b818-3d39ae2d9f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (18180, 15)\n",
      "Cleaned dataset shape: (12657, 15)\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(df, columns):\n",
    "    df_clean = df.copy()\n",
    "    for col in columns:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        # Keep rows within the bounds for the current column\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "# Define numerical columns from which to remove outliers\n",
    "# Excluding 'stars' and 'recipe_number'\n",
    "columns_to_clean = [\"user_reputation\", \"reply_count\", \"thumbs_up\", \"thumbs_down\", \"best_score\"]\n",
    "\n",
    "# Remove outliers\n",
    "df_clean = remove_outliers(df, columns_to_clean)\n",
    "\n",
    "# Print the shapes of the original and cleaned datasets\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"Cleaned dataset shape:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ee6ec30-ddc8-47c4-9dd5-dd1c53972242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of numeric columns:\n",
      "Unnamed: 0         1.945846\n",
      "recipe_number      0.587924\n",
      "recipe_code        3.105770\n",
      "user_reputation    0.000000\n",
      "reply_count        0.000000\n",
      "thumbs_up          0.000000\n",
      "thumbs_down        0.000000\n",
      "stars             -2.315872\n",
      "best_score         0.000000\n",
      "dtype: float64\n",
      "Applied Box-Cox to 'Unnamed: 0' with shift 1 and lambda 0.1059\n",
      "No transformation needed for 'Unnamed: 0'\n",
      "No transformation needed for 'recipe_number'\n",
      "Applied Box-Cox to 'recipe_code' with lambda 0.2571\n",
      "No transformation needed for 'recipe_code'\n",
      "No transformation needed for 'user_reputation'\n",
      "No transformation needed for 'reply_count'\n",
      "No transformation needed for 'thumbs_up'\n",
      "No transformation needed for 'thumbs_down'\n",
      "Applied square transformation to 'stars'\n",
      "No transformation needed for 'best_score'\n",
      "\n",
      "Transformed DataFrame columns:\n",
      "Index(['Unnamed: 0', 'recipe_number', 'recipe_code', 'recipe_name',\n",
      "       'comment_id', 'user_id', 'user_name', 'user_reputation', 'created_at',\n",
      "       'reply_count', 'thumbs_up', 'thumbs_down', 'stars', 'best_score',\n",
      "       'text', 'Unnamed: 0_boxcox', 'recipe_code_boxcox', 'stars_square'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Assume df_clean is your cleaned DataFrame\n",
    "# Select numeric columns\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Compute skewness for each numeric column\n",
    "skewness = df_clean[numeric_cols].skew()\n",
    "print(\"Skewness of numeric columns:\")\n",
    "print(skewness)\n",
    "\n",
    "# Define thresholds for high skewness\n",
    "right_threshold = 1   # right-skewed if skewness > 1\n",
    "left_threshold = -1   # left-skewed if skewness < -1\n",
    "\n",
    "# Dictionaries to store transformation parameters\n",
    "boxcox_lambdas = {}\n",
    "\n",
    "# Loop over each numeric column\n",
    "for col in numeric_cols:\n",
    "    col_skew = skewness[col]\n",
    "    # For right-skewed columns: use Box-Cox transformation\n",
    "    if col_skew > right_threshold:\n",
    "        # Box-Cox requires strictly positive values. If not, shift the data.\n",
    "        if (df_clean[col] <= 0).any():\n",
    "            shift = abs(df_clean[col].min()) + 1\n",
    "            data = df_clean[col] + shift\n",
    "            transformed, lmbda = boxcox(data)\n",
    "            print(f\"Applied Box-Cox to '{col}' with shift {shift} and lambda {lmbda:.4f}\")\n",
    "        else:\n",
    "            transformed, lmbda = boxcox(df_clean[col])\n",
    "            print(f\"Applied Box-Cox to '{col}' with lambda {lmbda:.4f}\")\n",
    "        # Save transformed data in a new column (you can choose to replace the original)\n",
    "        df_clean[col + '_boxcox'] = transformed\n",
    "        boxcox_lambdas[col] = lmbda\n",
    "         # For left-skewed columns: use square transformation\n",
    "    if col_skew < left_threshold:\n",
    "        df_clean[col + '_square'] = df_clean[col] ** 2\n",
    "        print(f\"Applied square transformation to '{col}'\")\n",
    "    else:\n",
    "        print(f\"No transformation needed for '{col}'\")\n",
    "\n",
    "# Optionally, inspect the new columns\n",
    "print(\"\\nTransformed DataFrame columns:\")\n",
    "print(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f827208-7fa7-48fc-a419-c54c9c894cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df[\"user_name\"] = encoder.fit_transform(df[\"user_name\"])  # Example categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7c962e8-0566-443e-a753-1eea456a9687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "x = df.drop(columns=['stars'])  \n",
    "y = df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfc6061d-2ef4-495c-83e1-e5643000036d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "5    13827\n",
       "0     1696\n",
       "4     1655\n",
       "3      490\n",
       "1      280\n",
       "2      232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06cba562-d890-460e-b29b-e6aac604de48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['Unnamed: 0', 'recipe_number', 'recipe_code', 'user_name', 'user_reputation', 'reply_count', 'thumbs_up', 'thumbs_down', 'best_score']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the target and select only numeric columns for feature selection\n",
    "X = df.drop(\"stars\", axis=1)\n",
    "X_numeric = X.select_dtypes(include='number')\n",
    "\n",
    "k = 9  # Number of features to select\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_new = selector.fit_transform(X_numeric, y)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X_numeric.columns[selector.get_support()]\n",
    "print(\"Selected Features:\", list(selected_feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f35679ff-5f88-4031-8964-8d1b995215cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_new=scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50148142-c831-4929-a3f8-9e10c64a6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2134e44-65b8-433b-b0e3-72e406006ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  x_train shape : (14544, 9)\n",
      "  x_test shape : (3636, 9)\n",
      "  y_train shape : (14544,)\n",
      "  y_test shape : (3636, 9)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "  x_train shape : {x_train.shape}\n",
    "  x_test shape : {x_test.shape}\n",
    "  y_train shape : {y_train.shape}\n",
    "  y_test shape : {x_test.shape}\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cd66d05-1942-41d2-9d12-7d0ce3d5e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b187e07d-d4af-4d67-acec-9d483e72aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Models with regularization\n",
    "models = {\n",
    "    \"Linear Regression (Ridge)\": Ridge(alpha=1.0),  # L2 regularization applied\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, \n",
    "                                           min_samples_split=5, min_samples_leaf=2, \n",
    "                                           random_state=42),  # Regularized through hyperparameters\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, \n",
    "                                                   max_depth=5, learning_rate=0.05, \n",
    "                                                   min_samples_split=5, min_samples_leaf=2,\n",
    "                                                   random_state=42),  # Regularized with smaller depth & learning rate\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, \n",
    "                            max_depth=5, learning_rate=0.05, \n",
    "                            reg_alpha=0.1, reg_lambda=0.1,  # L1 and L2 regularization\n",
    "                            random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, min_samples_split=5, \n",
    "                                           min_samples_leaf=2, random_state=42)  # Regularized with pruning\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf81a76a-4639-4c92-9174-e758566e4bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression (Ridge)...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training Gradient Boosting...\n",
      "\n",
      "Training XGBoost...\n",
      "\n",
      "Training Decision Tree...\n",
      "\n",
      "Model Evaluation Results:\n",
      "                       Model  Train MSE  Test MSE  Train RMSE  Test RMSE  \\\n",
      "1              Random Forest   1.672203  2.023961    1.293137   1.422660   \n",
      "3                    XGBoost   1.917187  2.088439    1.384625   1.445143   \n",
      "2          Gradient Boosting   1.905757  2.092460    1.380492   1.446534   \n",
      "4              Decision Tree   2.126988  2.180329    1.458420   1.476594   \n",
      "0  Linear Regression (Ridge)   2.328064  2.283835    1.525800   1.511236   \n",
      "\n",
      "   Train R²   Test R²    R² Gap  \n",
      "1  0.303208  0.132344  0.170863  \n",
      "3  0.201125  0.104703  0.096422  \n",
      "2  0.205888  0.102979  0.102909  \n",
      "4  0.113703  0.065310  0.048393  \n",
      "0  0.029916  0.020938  0.008978  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through the models and evaluate\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate metrics for training and testing sets\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Calculate the R² gap to detect overfitting\n",
    "    r2_gap = abs(train_r2 - test_r2)\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train MSE\": train_mse,\n",
    "        \"Test MSE\": test_mse,\n",
    "        \"Train RMSE\": train_rmse,\n",
    "        \"Test RMSE\": test_rmse,\n",
    "        \"Train R²\": train_r2,\n",
    "        \"Test R²\": test_r2,\n",
    "        \"R² Gap\": r2_gap\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by=\"Test R²\", ascending=False, inplace=True)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfa497b5-77a7-46ed-aa0b-83b3a1bb2235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "\n",
      "Best Hyperparameters: {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],            # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],                 # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],                  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],                    # Minimum samples required in a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None],           # Number of features to consider for the best split\n",
    "    'bootstrap': [True, False]                        # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV for faster tuning\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n",
    "                                   n_iter=50, cv=3, n_jobs=-1, verbose=2, scoring='r2', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9b919d5-cbbb-4958-b24e-815d98cbd5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "\n",
      "Best Hyperparameters: {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],            # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],                 # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],                  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],                    # Minimum samples required in a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None],           # Number of features to consider for the best split\n",
    "    'bootstrap': [True, False]                        # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV for faster tuning\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n",
    "                                   n_iter=50, cv=3, n_jobs=-1, verbose=2, scoring='r2', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff06f9-0d75-4d49-b1a0-86553e57da64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
