{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e57c86-5661-405d-8314-63f10d88a386",
   "metadata": {},
   "source": [
    "Recipe Reviews and User Feedbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686311c-7caa-49c0-be3f-25b65d686bd0",
   "metadata": {},
   "source": [
    "Name: Joel K Abraham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e89df-0572-4e96-8aab-d5e8c61d39cc",
   "metadata": {},
   "source": [
    "Organisation: Entri Elevate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873145c-d176-49d5-8784-86eaf62b2424",
   "metadata": {},
   "source": [
    "Date:: 18/03/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b71a4-cefe-4d46-8863-e3d877615c53",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "The Recipe Reviews dataset comprises over 18,000 user-generated reviews that capture detailed information about recipes and user interactions. It includes identifiers such as recipe_number, recipe_code, and recipe_name, along with review-specific data like unique comment IDs, timestamps, reply counts, and engagement metrics (thumbs up and thumbs down). Additionally, it provides insights into user behavior through user IDs, names, and reputation scores, and features numerical ratings like stars and best_score, as well as the actual review text. This rich dataset is ideal for analyzing sentiment, user engagement, and trends in culinary feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8258b-9143-49e9-86ea-e5817ebf7e90",
   "metadata": {},
   "source": [
    "Objective\n",
    "\n",
    "The objective of the Recipe Reviews dataset is to provide a rich, multifaceted view of user interactions with culinary recipes, enabling the analysis of sentiment, engagement, and review quality. It is designed to support research in understanding how factors like user reputation, review ratings (such as stars and best_score), and textual feedback correlate with overall user satisfaction and recipe performance. This dataset facilitates various analytical tasks—from sentiment analysis and trend detection to the development of recommendation systems—thus offering valuable insights for both data scientists and culinary professionals looking to enhance user experience and improve recipe curation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d40c504-4ac7-491f-9c13-225bd8082b14",
   "metadata": {},
   "source": [
    "Data Description\n",
    "\n",
    "Unnamed: 0: An index column generated during data export or import.\n",
    "recipe_number: A numerical identifier for the recipe.\n",
    "recipe_code: A code representing the recipe, likely used for internal identification.\n",
    "recipe_name: The name or title of the recipe.\n",
    "comment_id: A unique identifier for each review or comment.\n",
    "user_id: A unique identifier for the user who submitted the review.\n",
    "user_name: The display name of the user.\n",
    "user_reputation: A numerical score indicating the credibility or influence of the user.\n",
    "created_at: A timestamp showing when the review was posted.\n",
    "reply_count: The number of replies or follow-up comments the review received.\n",
    "thumbs_up: The count of positive feedback received for the review.\n",
    "thumbs_down: The count of negative feedback received for the review.\n",
    "stars: The rating given to the recipe, typically on a scale (e.g., 1-5 stars).\n",
    "best_score: A computed score that might reflect the quality or relevance of the review.\n",
    "text: The actual textual content of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a279f3a-f077-4cc2-aff0-728a12bc51f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18182 entries, 0 to 18181\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       18182 non-null  int64 \n",
      " 1   recipe_number    18182 non-null  int64 \n",
      " 2   recipe_code      18182 non-null  int64 \n",
      " 3   recipe_name      18182 non-null  object\n",
      " 4   comment_id       18182 non-null  object\n",
      " 5   user_id          18182 non-null  object\n",
      " 6   user_name        18182 non-null  object\n",
      " 7   user_reputation  18182 non-null  int64 \n",
      " 8   created_at       18182 non-null  int64 \n",
      " 9   reply_count      18182 non-null  int64 \n",
      " 10  thumbs_up        18182 non-null  int64 \n",
      " 11  thumbs_down      18182 non-null  int64 \n",
      " 12  stars            18182 non-null  int64 \n",
      " 13  best_score       18182 non-null  int64 \n",
      " 14  text             18180 non-null  object\n",
      "dtypes: int64(10), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>recipe_number</th>\n",
       "      <th>recipe_code</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_reputation</th>\n",
       "      <th>created_at</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>thumbs_down</th>\n",
       "      <th>stars</th>\n",
       "      <th>best_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM</td>\n",
       "      <td>u_9iFLIhMa8QaG</td>\n",
       "      <td>Jeri326</td>\n",
       "      <td>1</td>\n",
       "      <td>1665619889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>527</td>\n",
       "      <td>I tweaked it a little, removed onions because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY</td>\n",
       "      <td>u_Lu6p25tmE77j</td>\n",
       "      <td>Mark467</td>\n",
       "      <td>50</td>\n",
       "      <td>1665277687</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>724</td>\n",
       "      <td>Bush used to have a white chili bean and it ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2FPrSGyTv7PQkZq37j92r9mYGkP</td>\n",
       "      <td>u_s0LwgpZ8Jsqq</td>\n",
       "      <td>Barbara566</td>\n",
       "      <td>10</td>\n",
       "      <td>1664404557</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>710</td>\n",
       "      <td>I have a very complicated white chicken chili ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2DzdSIgV9qNiuBaLoZ7JQaartoC</td>\n",
       "      <td>u_fqrybAdYjgjG</td>\n",
       "      <td>jeansch123</td>\n",
       "      <td>1</td>\n",
       "      <td>1661787808</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>In your introduction, you mentioned cream chee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14299</td>\n",
       "      <td>Creamy White Chili</td>\n",
       "      <td>sp_aUSaElGf_14299_c_2DtZJuRQYeTFwXBoZRfRhBPEXjI</td>\n",
       "      <td>u_XXWKwVhKZD69</td>\n",
       "      <td>camper77</td>\n",
       "      <td>10</td>\n",
       "      <td>1664913823</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>820</td>\n",
       "      <td>Wonderful! I made this for a &amp;#34;Chili/Stew&amp;#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  recipe_number  recipe_code         recipe_name  \\\n",
       "0           0              1        14299  Creamy White Chili   \n",
       "1           1              1        14299  Creamy White Chili   \n",
       "2           2              1        14299  Creamy White Chili   \n",
       "3           3              1        14299  Creamy White Chili   \n",
       "4           4              1        14299  Creamy White Chili   \n",
       "\n",
       "                                        comment_id         user_id  \\\n",
       "0  sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM  u_9iFLIhMa8QaG   \n",
       "1  sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY  u_Lu6p25tmE77j   \n",
       "2  sp_aUSaElGf_14299_c_2FPrSGyTv7PQkZq37j92r9mYGkP  u_s0LwgpZ8Jsqq   \n",
       "3  sp_aUSaElGf_14299_c_2DzdSIgV9qNiuBaLoZ7JQaartoC  u_fqrybAdYjgjG   \n",
       "4  sp_aUSaElGf_14299_c_2DtZJuRQYeTFwXBoZRfRhBPEXjI  u_XXWKwVhKZD69   \n",
       "\n",
       "    user_name  user_reputation  created_at  reply_count  thumbs_up  \\\n",
       "0     Jeri326                1  1665619889            0          0   \n",
       "1     Mark467               50  1665277687            0          7   \n",
       "2  Barbara566               10  1664404557            0          3   \n",
       "3  jeansch123                1  1661787808            2          2   \n",
       "4    camper77               10  1664913823            1          7   \n",
       "\n",
       "   thumbs_down  stars  best_score  \\\n",
       "0            0      5         527   \n",
       "1            0      5         724   \n",
       "2            0      5         710   \n",
       "3            0      0         581   \n",
       "4            0      0         820   \n",
       "\n",
       "                                                text  \n",
       "0  I tweaked it a little, removed onions because ...  \n",
       "1  Bush used to have a white chili bean and it ma...  \n",
       "2  I have a very complicated white chicken chili ...  \n",
       "3  In your introduction, you mentioned cream chee...  \n",
       "4  Wonderful! I made this for a &#34;Chili/Stew&#...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Recipe_Reviews.csv\", encoding=\"ISO-8859-1\")  # Change file format if needed\n",
    "\n",
    "# Display basic info\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7150dacb-827b-4995-95bd-91274c9fe8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0         0\n",
      "recipe_number      0\n",
      "recipe_code        0\n",
      "recipe_name        0\n",
      "comment_id         0\n",
      "user_id            0\n",
      "user_name          0\n",
      "user_reputation    0\n",
      "created_at         0\n",
      "reply_count        0\n",
      "thumbs_up          0\n",
      "thumbs_down        0\n",
      "stars              0\n",
      "best_score         0\n",
      "text               2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3307a71-4a8f-44e0-975d-e397552a91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows/columns with excessive missing data\n",
    "df.dropna(subset=[\"user_id\", \"text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b275ef1-6c2a-4ca3-99f9-ede8f2ca203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "18177    False\n",
       "18178    False\n",
       "18179    False\n",
       "18180    False\n",
       "18181    False\n",
       "Length: 18180, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69510b4-5915-4848-abca-2e7ce643644d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a7c68c-31cd-432c-8489-b0b2248ec5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1970-01-01 00:00:01.665619889\n",
       "1       1970-01-01 00:00:01.665277687\n",
       "2       1970-01-01 00:00:01.664404557\n",
       "3       1970-01-01 00:00:01.661787808\n",
       "4       1970-01-01 00:00:01.664913823\n",
       "                     ...             \n",
       "18177   1970-01-01 00:00:01.622717977\n",
       "18178   1970-01-01 00:00:01.613036720\n",
       "18179   1970-01-01 00:00:01.622717844\n",
       "18180   1970-01-01 00:00:01.622717233\n",
       "18181   1970-01-01 00:00:01.622717625\n",
       "Name: created_at, Length: 18180, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "df[\"created_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73292e81-f874-4633-862a-1305b15db167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_reputation: 1246 outliers\n",
      "reply_count: 230 outliers\n",
      "thumbs_up: 4080 outliers\n",
      "thumbs_down: 2396 outliers\n",
      "stars: 4353 outliers\n",
      "best_score: 4180 outliers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to count outliers using the IQR method\n",
    "def count_outliers(df, columns):\n",
    "    outlier_counts = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        outlier_counts[col] = len(outliers)\n",
    "    return outlier_counts\n",
    "\n",
    "# Define numerical columns to check for outliers\n",
    "numerical_columns = [\"user_reputation\", \"reply_count\", \"thumbs_up\", \"thumbs_down\", \"stars\", \"best_score\"]\n",
    "\n",
    "# Get the counts of outliers\n",
    "outlier_counts = count_outliers(df, numerical_columns)\n",
    "\n",
    "# Print out the results\n",
    "for col, count in outlier_counts.items():\n",
    "    print(f\"{col}: {count} outliers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce5d30b2-7ae0-47f0-a35a-cb09b36aa3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          2.112885\n",
       "recipe_number       0.458756\n",
       "recipe_code         3.443614\n",
       "user_reputation    33.716657\n",
       "reply_count        11.282445\n",
       "thumbs_up           8.413665\n",
       "thumbs_down        17.889305\n",
       "stars              -2.128418\n",
       "best_score          3.402349\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include = [\"number\"]).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e614694d-432f-40cd-b818-3d39ae2d9f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (18180, 15)\n",
      "Cleaned dataset shape: (12657, 15)\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(df, columns):\n",
    "    df_clean = df.copy()\n",
    "    for col in columns:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        # Keep rows within the bounds for the current column\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "# Define numerical columns from which to remove outliers\n",
    "# Excluding 'stars' and 'recipe_number'\n",
    "columns_to_clean = [\"user_reputation\", \"reply_count\", \"thumbs_up\", \"thumbs_down\", \"best_score\"]\n",
    "\n",
    "# Remove outliers\n",
    "df_clean = remove_outliers(df, columns_to_clean)\n",
    "\n",
    "# Print the shapes of the original and cleaned datasets\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"Cleaned dataset shape:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ee6ec30-ddc8-47c4-9dd5-dd1c53972242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of numeric columns:\n",
      "Unnamed: 0         1.945846\n",
      "recipe_number      0.587924\n",
      "recipe_code        3.105770\n",
      "user_reputation    0.000000\n",
      "reply_count        0.000000\n",
      "thumbs_up          0.000000\n",
      "thumbs_down        0.000000\n",
      "stars             -2.315872\n",
      "best_score         0.000000\n",
      "dtype: float64\n",
      "Applied Box-Cox to 'Unnamed: 0' with shift 1 and lambda 0.1059\n",
      "No transformation needed for 'Unnamed: 0'\n",
      "No transformation needed for 'recipe_number'\n",
      "Applied Box-Cox to 'recipe_code' with lambda 0.2571\n",
      "No transformation needed for 'recipe_code'\n",
      "No transformation needed for 'user_reputation'\n",
      "No transformation needed for 'reply_count'\n",
      "No transformation needed for 'thumbs_up'\n",
      "No transformation needed for 'thumbs_down'\n",
      "Applied square transformation to 'stars'\n",
      "No transformation needed for 'best_score'\n",
      "\n",
      "Transformed DataFrame columns:\n",
      "Index(['Unnamed: 0', 'recipe_number', 'recipe_code', 'recipe_name',\n",
      "       'comment_id', 'user_id', 'user_name', 'user_reputation', 'created_at',\n",
      "       'reply_count', 'thumbs_up', 'thumbs_down', 'stars', 'best_score',\n",
      "       'text', 'Unnamed: 0_boxcox', 'recipe_code_boxcox', 'stars_square'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Assume df_clean is your cleaned DataFrame\n",
    "# Select numeric columns\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Compute skewness for each numeric column\n",
    "skewness = df_clean[numeric_cols].skew()\n",
    "print(\"Skewness of numeric columns:\")\n",
    "print(skewness)\n",
    "\n",
    "# Define thresholds for high skewness\n",
    "right_threshold = 1   # right-skewed if skewness > 1\n",
    "left_threshold = -1   # left-skewed if skewness < -1\n",
    "\n",
    "# Dictionaries to store transformation parameters\n",
    "boxcox_lambdas = {}\n",
    "\n",
    "# Loop over each numeric column\n",
    "for col in numeric_cols:\n",
    "    col_skew = skewness[col]\n",
    "    # For right-skewed columns: use Box-Cox transformation\n",
    "    if col_skew > right_threshold:\n",
    "        # Box-Cox requires strictly positive values. If not, shift the data.\n",
    "        if (df_clean[col] <= 0).any():\n",
    "            shift = abs(df_clean[col].min()) + 1\n",
    "            data = df_clean[col] + shift\n",
    "            transformed, lmbda = boxcox(data)\n",
    "            print(f\"Applied Box-Cox to '{col}' with shift {shift} and lambda {lmbda:.4f}\")\n",
    "        else:\n",
    "            transformed, lmbda = boxcox(df_clean[col])\n",
    "            print(f\"Applied Box-Cox to '{col}' with lambda {lmbda:.4f}\")\n",
    "        # Save transformed data in a new column (you can choose to replace the original)\n",
    "        df_clean[col + '_boxcox'] = transformed\n",
    "        boxcox_lambdas[col] = lmbda\n",
    "         # For left-skewed columns: use square transformation\n",
    "    if col_skew < left_threshold:\n",
    "        df_clean[col + '_square'] = df_clean[col] ** 2\n",
    "        print(f\"Applied square transformation to '{col}'\")\n",
    "    else:\n",
    "        print(f\"No transformation needed for '{col}'\")\n",
    "\n",
    "# Optionally, inspect the new columns\n",
    "print(\"\\nTransformed DataFrame columns:\")\n",
    "print(df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7c962e8-0566-443e-a753-1eea456a9687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "x = df.drop(columns=['stars'])  \n",
    "y = df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfc6061d-2ef4-495c-83e1-e5643000036d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "5    13827\n",
       "0     1696\n",
       "4     1655\n",
       "3      490\n",
       "1      280\n",
       "2      232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43f0ca0f-1bdc-4477-873d-f13b97f09968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "x_resampled, y_resampled = smote.fit_resample(x.select_dtypes(include='number'), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "945b39e0-ceca-44dd-8267-6f3a0c92bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE:\n",
      "stars\n",
      "5    13827\n",
      "0    13827\n",
      "4    13827\n",
      "3    13827\n",
      "1    13827\n",
      "2    13827\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"After SMOTE:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06cba562-d890-460e-b29b-e6aac604de48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['Unnamed: 0', 'recipe_number', 'recipe_code', 'user_reputation', 'reply_count', 'thumbs_up', 'thumbs_down', 'best_score']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:776: UserWarning: k=9 is greater than n_features=8. All the features will be returned.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the target and select only numeric columns for feature selection\n",
    "X = df.drop(\"stars\", axis=1)\n",
    "X_numeric = X.select_dtypes(include='number')\n",
    "\n",
    "k = 9  # Number of features to select\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_new = selector.fit_transform(X_numeric, y)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X_numeric.columns[selector.get_support()]\n",
    "print(\"Selected Features:\", list(selected_feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f35679ff-5f88-4031-8964-8d1b995215cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_new=scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50148142-c831-4929-a3f8-9e10c64a6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2134e44-65b8-433b-b0e3-72e406006ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  x_train shape : (14544, 8)\n",
      "  x_test shape : (3636, 8)\n",
      "  y_train shape : (14544,)\n",
      "  y_test shape : (3636, 8)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "  x_train shape : {x_train.shape}\n",
    "  x_test shape : {x_test.shape}\n",
    "  y_train shape : {y_train.shape}\n",
    "  y_test shape : {x_test.shape}\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cd66d05-1942-41d2-9d12-7d0ce3d5e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define five classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Define models with regularization parameters applied where applicable\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "                                penalty='l2',      # L2 regularization\n",
    "                                C=1.0,             # Regularization strength (adjust as needed)\n",
    "                                solver='lbfgs', \n",
    "                                max_iter=1000, \n",
    "                                random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(\n",
    "                                random_state=42, \n",
    "                                max_depth=10,      # Limit tree depth to reduce overfitting\n",
    "                                min_samples_split=5),  # Increase min samples to split a node\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "                                n_estimators=100, \n",
    "                                random_state=42, \n",
    "                                max_depth=10,      # Limit depth of trees for regularization\n",
    "                                min_samples_split=5),\n",
    "    'Support Vector Machine': SVC(\n",
    "                                C=1.0,             # Regularization parameter (adjust as needed)\n",
    "                                kernel='rbf', \n",
    "                                gamma='scale', \n",
    "                                random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51ef3f2a-106b-4970-ac26-97395220cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression -\n",
      "    Train Accuracy: 0.7633, Precision: 0.6263, Recall: 0.7633, F1: 0.6676\n",
      "    Test Accuracy:  0.7561, Precision: 0.6013, Recall: 0.7561, F1: 0.6572\n",
      "\n",
      "Decision Tree -\n",
      "    Train Accuracy: 0.7948, Precision: 0.7825, Recall: 0.7948, F1: 0.7374\n",
      "    Test Accuracy:  0.7588, Precision: 0.6709, Recall: 0.7588, F1: 0.6881\n",
      "\n",
      "Random Forest -\n",
      "    Train Accuracy: 0.7855, Precision: 0.8156, Recall: 0.7855, F1: 0.7120\n",
      "    Test Accuracy:  0.7627, Precision: 0.6667, Recall: 0.7627, F1: 0.6744\n",
      "\n",
      "Support Vector Machine -\n",
      "    Train Accuracy: 0.7673, Precision: 0.7752, Recall: 0.7673, F1: 0.6744\n",
      "    Test Accuracy:  0.7577, Precision: 0.6104, Recall: 0.7577, F1: 0.6590\n",
      "\n",
      "K-Nearest Neighbors -\n",
      "    Train Accuracy: 0.7972, Precision: 0.7584, Recall: 0.7972, F1: 0.7619\n",
      "    Test Accuracy:  0.7398, Precision: 0.6661, Recall: 0.7398, F1: 0.6927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score with zero_division set to 0\n",
    "    train_precision = precision_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'train_precision': train_precision,\n",
    "        'train_recall': train_recall,\n",
    "        'train_f1': train_f1,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name} -\")\n",
    "    print(f\"    Train Accuracy: {train_acc:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "    print(f\"    Test Accuracy:  {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83464892-6a8e-4519-8fa2-078a31b3974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Best Parameters for Random Forest: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Cross-validation Accuracy: 0.7707645764576458\n",
      "\n",
      "Test Metrics for the Tuned Random Forest:\n",
      "Test Accuracy:  0.7660\n",
      "Test Precision: 0.6868\n",
      "Test Recall:    0.7660\n",
      "Test F1 Score:  0.6858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the parameter grid for Random Forest tuning\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Setup GridSearchCV with 5-fold cross-validation\n",
    "grid_search_rf = GridSearchCV(estimator=rf,\n",
    "                              param_grid=param_grid_rf,\n",
    "                              cv=3,\n",
    "                              n_jobs=-1,\n",
    "                              scoring='accuracy',\n",
    "                              verbose=1)\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search_rf.fit(x_train, y_train)\n",
    "\n",
    "# Output the best parameters and cross-validation score\n",
    "print(\"Best Parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "print(\"Best Cross-validation Accuracy:\", grid_search_rf.best_score_)\n",
    "\n",
    "# Evaluate the best estimator on the test set\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "y_pred_test = best_rf.predict(x_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_precision = precision_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "test_recall = recall_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\nTest Metrics for the Tuned Random Forest:\")\n",
    "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall:    {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score:  {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe31a4-b636-4a3e-9cbd-0dd3bfdbb4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
